{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/Users/professortu/Documents/BOEK')\n",
    "import sys\n",
    "sys.path.append(r'/Users/professortu/Documents/BOEK')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['person', 'lnwage', 'educ', 'exp', 'ability', 'moedu', 'faedu', 'sibs'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('KTdata.xlsx')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    const  educ  exp  ability  moedu  faedu  sibs\n",
      "0     1.0    13    1     1.00     12     12     1\n",
      "1     1.0    15    4     1.50     12     12     1\n",
      "2     1.0    10    1    -0.36     12     12     1\n",
      "3     1.0    12    1     0.26     12     10     4\n",
      "4     1.0    15    2     0.30     12     12     1\n",
      "5     1.0    15    2     0.44     12     16     2\n",
      "6     1.0    15    3     0.91     12     12     1\n",
      "7     1.0    13    4     0.51     12     15     2\n",
      "8     1.0    13    2     0.86     12     12     2\n",
      "9     1.0    11    5     0.26     12     12     1\n",
      "10    1.0    12    1     1.82     16     17     2\n",
      "11    1.0    13    4    -1.30     13     12     5\n",
      "12    1.0    12    3    -0.63     12     12     2\n",
      "13    1.0    12    6    -0.36     10     12     2\n",
      "14    1.0    12    3     0.28     12     12     3\n"
     ]
    }
   ],
   "source": [
    "# Prepare y and X1\n",
    "y = data['lnwage']\n",
    "X1 = data[['educ', 'exp', 'ability']]\n",
    "X1 = sm.add_constant(X1)\n",
    "\n",
    "# Prepare X2\n",
    "X2 = data[['moedu', 'faedu', 'sibs']]\n",
    "\n",
    "# Combine X1 and X2\n",
    "X = pd.concat([X1, X2], axis=1)\n",
    "\n",
    "# Print the adjusted X\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question a:\n",
    "Compute the least squares regression coefficients in the regression of $y$ on $X_1$. Report the coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 lnwage   R-squared:                       0.183\n",
      "Model:                            OLS   Adj. R-squared:                 -0.039\n",
      "Method:                 Least Squares   F-statistic:                    0.8232\n",
      "Date:                Mon, 23 Dec 2024   Prob (F-statistic):              0.508\n",
      "Time:                        00:14:36   Log-Likelihood:                 1.0519\n",
      "No. Observations:                  15   AIC:                             5.896\n",
      "Df Residuals:                      11   BIC:                             8.728\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.6636      0.619      2.690      0.021       0.302       3.025\n",
      "educ           0.0145      0.049      0.297      0.772      -0.093       0.122\n",
      "exp            0.0710      0.048      1.479      0.167      -0.035       0.177\n",
      "ability        0.0266      0.099      0.269      0.793      -0.192       0.245\n",
      "==============================================================================\n",
      "Omnibus:                        1.923   Durbin-Watson:                   1.489\n",
      "Prob(Omnibus):                  0.382   Jarque-Bera (JB):                1.143\n",
      "Skew:                           0.668   Prob(JB):                        0.565\n",
      "Kurtosis:                       2.787   Cond. No.                         121.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:418: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=15 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "model_a = sm.OLS(y, X1).fit()\n",
    "print(model_a.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question b:\n",
    "Compute the least squares regression coefficients in the regression of $y$ on $X_1$ and $X_2$. Report the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 lnwage   R-squared:                       0.625\n",
      "Model:                            OLS   Adj. R-squared:                  0.344\n",
      "Method:                 Least Squares   F-statistic:                     2.223\n",
      "Date:                Mon, 23 Dec 2024   Prob (F-statistic):              0.146\n",
      "Time:                        00:32:46   Log-Likelihood:                 6.8909\n",
      "No. Observations:                  15   AIC:                            0.2183\n",
      "Df Residuals:                       8   BIC:                             5.175\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.7764      1.002     -0.775      0.461      -3.087       1.535\n",
      "educ           0.0402      0.041      0.981      0.355      -0.054       0.135\n",
      "exp            0.1213      0.042      2.861      0.021       0.024       0.219\n",
      "ability       -0.0414      0.106     -0.390      0.707      -0.286       0.203\n",
      "moedu          0.1815      0.077      2.351      0.047       0.003       0.360\n",
      "faedu         -0.0197      0.041     -0.481      0.644      -0.114       0.075\n",
      "sibs           0.0144      0.062      0.232      0.822      -0.129       0.158\n",
      "==============================================================================\n",
      "Omnibus:                        4.843   Durbin-Watson:                   1.972\n",
      "Prob(Omnibus):                  0.089   Jarque-Bera (JB):                2.203\n",
      "Skew:                           0.465   Prob(JB):                        0.332\n",
      "Kurtosis:                       4.631   Cond. No.                         412.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:418: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=15 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "model_b = sm.OLS(y, X).fit()\n",
    "print(model_b.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question c:\n",
    "**Regress each of the three variables in** $X_2$ **on all the variables in** $X_1$ **and compute the residuals from each regression. Arrange these new variables in the** $15 \\times 3$ **matrix** $\\tilde{X}_2$. **What are the sample means of these three variables? Explain the finding.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residuals Matrix (X~2):\n",
      "[[-1.00237722 -1.22150878 -0.68216791]\n",
      " [-0.18294807 -1.71475472 -0.01293517]\n",
      " [-0.69940629  0.04565311 -1.69310393]\n",
      " [-0.74823444 -2.54894445  1.74593351]\n",
      " [-0.07794267 -0.66525293 -1.21534339]\n",
      " [-0.15273807  3.21256759 -0.10061506]\n",
      " [-0.1357879  -1.19873093 -0.6059444 ]\n",
      " [ 0.06355362  2.20274575  0.24481681]\n",
      " [-0.65953284 -1.10045385  0.31261505]\n",
      " [ 0.18275722 -0.52668416 -0.78149877]\n",
      " [ 2.41833118  3.08962704  1.02433486]\n",
      " [ 2.03055121  0.7823519   1.76154346]\n",
      " [ 0.26334854  0.22551886 -0.76438827]\n",
      " [-1.07675276 -0.01348665 -0.21459264]\n",
      " [-0.22282152 -0.56864777  0.98134585]]\n",
      "\n",
      "Sample Means of Each Variable in X~2:\n",
      "[-2.13162821e-15  0.00000000e+00 -1.74675089e-15]\n"
     ]
    }
   ],
   "source": [
    "residuals_matrix = []\n",
    "\n",
    "for col in X2.columns:\n",
    "    model = sm.OLS(data[col], X1).fit()\n",
    "    residuals = model.resid\n",
    "    residuals_matrix.append(residuals)\n",
    "\n",
    "X_tilde_2 = np.column_stack(residuals_matrix)\n",
    "\n",
    "sample_means = X_tilde_2.mean(axis=0)\n",
    "\n",
    "print(\"Residuals Matrix (X~2):\")\n",
    "print(X_tilde_2)\n",
    "print(\"\\nSample Means of Each Variable in X~2:\")\n",
    "print(sample_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question d:\n",
    "\n",
    "**Compute the** $R^2$ **for the regression of** $y$ **on** $X_1$ **and** $X_2$. **Repeat the computation for the case in which the constant term is omitted from** $X_1$. **What happens to** $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_total: 0.9346933333333335\n",
      "SS_residual: 0.3504248263194957\n",
      "R-squared (manual): 0.6250911247330722\n",
      "R-squared (model): 0.6250911247330722\n"
     ]
    }
   ],
   "source": [
    "#y on X1 and X2\n",
    "# Extract y_actual (observed values)\n",
    "y_actual = y.values\n",
    "\n",
    "# Extract y_predicted (fitted values)\n",
    "y_predicted = model_b.fittedvalues.values\n",
    "\n",
    "# Calculate the mean of y_actual\n",
    "y_mean = np.mean(y_actual)\n",
    "\n",
    "# Calculate SS_total (total sum of squares)\n",
    "SS_total = np.sum((y_actual - y_mean) ** 2)\n",
    "\n",
    "# Calculate SS_residual (residual sum of squares)\n",
    "SS_residual = np.sum((y_actual - y_predicted) ** 2)\n",
    "\n",
    "# Calculate R-squared manually\n",
    "R_squared = 1 - (SS_residual / SS_total)\n",
    "\n",
    "# Print the results\n",
    "print(\"SS_total:\", SS_total)\n",
    "print(\"SS_residual:\", SS_residual)\n",
    "print(\"R-squared (manual):\", R_squared)\n",
    "print(\"R-squared (model):\", model_b.rsquared) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 lnwage   R-squared (uncentered):                   0.994\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.990\n",
      "Method:                 Least Squares   F-statistic:                              255.5\n",
      "Date:                Mon, 23 Dec 2024   Prob (F-statistic):                    1.57e-09\n",
      "Time:                        01:13:32   Log-Likelihood:                          6.3484\n",
      "No. Observations:                  15   AIC:                                    -0.6967\n",
      "Df Residuals:                       9   BIC:                                      3.552\n",
      "Df Model:                           6                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "educ           0.0188      0.030      0.635      0.541      -0.048       0.086\n",
      "exp            0.1092      0.039      2.834      0.020       0.022       0.196\n",
      "ability       -0.0014      0.091     -0.015      0.988      -0.206       0.204\n",
      "moedu          0.1354      0.048      2.820      0.020       0.027       0.244\n",
      "faedu         -0.0153      0.040     -0.387      0.708      -0.105       0.074\n",
      "sibs           0.0286      0.058      0.491      0.635      -0.103       0.160\n",
      "==============================================================================\n",
      "Omnibus:                        8.320   Durbin-Watson:                   2.080\n",
      "Prob(Omnibus):                  0.016   Jarque-Bera (JB):                5.027\n",
      "Skew:                           0.929   Prob(JB):                       0.0810\n",
      "Kurtosis:                       5.143   Cond. No.                         41.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:418: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=15 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#y on X1 and X2 without constant\n",
    "X11 = data[['educ', 'exp', 'ability']]\n",
    "X12 = pd.concat([X11, X2], axis=1)\n",
    "model_c = sm.OLS(y, X12).fit()\n",
    "print(model_c.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_total: 0.9346933333333335\n",
      "SS_residual: 0.37671184257317875\n",
      "R-squared (manual): 0.5969674446807738\n",
      "R-squared (model): 0.9941638042902796\n"
     ]
    }
   ],
   "source": [
    "# Extract y_predicted (fitted values)\n",
    "y_predicted_c = model_c.fittedvalues.values\n",
    "# Calculate SS_residual (residual sum of squares)\n",
    "SS_residual_c = np.sum((y_actual - y_predicted_c) ** 2)\n",
    "# Calculate R-squared manually\n",
    "R_squared_c = 1 - (SS_residual_c / SS_total)\n",
    "\n",
    "# Print the results\n",
    "print(\"SS_total:\", SS_total)\n",
    "print(\"SS_residual:\", SS_residual_c)\n",
    "print(\"R-squared (manual):\", R_squared_c)\n",
    "print(\"R-squared (model):\", model_c.rsquared) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question e:\n",
    "Compute the adjusted $R^2$ for the full regression including the constant term. Interpret your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (adjusted, manual): 0.3439094682828763\n",
      "R-squared (adjusted, model): 0.3439094682828763\n"
     ]
    }
   ],
   "source": [
    "# Number of observations and independent variables\n",
    "n = len(y_actual)  # Number of observations\n",
    "k = X.shape[1] - 1  # Number of independent variables (excluding constant)\n",
    "# Calculate Adjusted R-squared manually\n",
    "R_squared_adj = 1-((1-R_squared)*(n-1))/(n-k-1)\n",
    "# Print results\n",
    "print(\"R-squared (adjusted, manual):\", R_squared_adj)\n",
    "print(\"R-squared (adjusted, model):\", model_b.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question f:\n",
    "Referring to the result in part c, regress $y$ on $X_1$ and $\\tilde{X}_2$. How do your results compare to the results of the regression of $y$ on $X_1$ and $X_2$? The comparison you are making is between the least squares coefficients when $y$ is regressed on $X_1$ and $M_1X_2$, and when $y$ is regressed on $X_1$ and $\\tilde{X}_2$. Derive the result theoretically. (Your numerical results should match the theory, of course.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
